# import streamlit as st
# from transformers import pipeline
# import json
# from gemini_integrated import JournalInsightGenerator
# import torch
# from transformers import AutoModelForSequenceClassification, BertTokenizer, pipeline

# #TODO: change import to gemini_2

# # # Step 1: Load Local Sentiment Analysis Model
# # @st.cache_resource
# # def load_local_model():
# #     # Using a pre-trained Hugging Face sentiment analysis model for simplicity
# #     return pipeline("sentiment-analysis")

# # local_model = load_local_model()

# # Step 2: Load Gemini Model
# @st.cache_resource
# def load_gemini_model():
#     generator = JournalInsightGenerator()
#     generator.one_shot_prompt()  # Initialize with one-shot prompt
#     return generator

# gemini_model = load_gemini_model()

# # Step 3: Streamlit App Layout
# st.title("AI-Powered Journaling Application")

# # Initialize session state for insights
# if "insights" not in st.session_state:
#     st.session_state.insights = {}

# # Text Area for Journaling
# journal_entry = st.text_area("Write your journal entry below:")

# # Buttons for actions
# analyze_button = st.button("Analyze Insights")
# download_button = st.button("Download Insights")

# # Placeholder for insights
# insights = {}

# # Step 4: Analyze Insights Button Logic
# if analyze_button:
#     if journal_entry.strip():
#         st.write("Analyzing your journal entry...")

#         # # Local Sentiment Analysis
#         # local_insights = local_model(journal_entry)
#         # st.write("Local Analysis Complete:", local_insights)

#         # Generate Insights using Gemini Model
#         # try:
#         #     gemini_insights = gemini_model.generate_journal_insights(journal_entry)
#         #     insights = {
#         #         # "local_analysis": local_insights,
#         #         "gemini_analysis": gemini_insights
#         #     }
#         #     st.write("Insights Generated by Gemini:")
#         #     st.json(gemini_insights)
#         # except Exception as e:
#         #     st.error(f"Failed to generate insights using Gemini: {str(e)}")

#         try:

#             topic_save_path = 'topic_model'
#             topic_model = AutoModelForSequenceClassification.from_pretrained(topic_save_path)
#             topic_tokenizer = BertTokenizer.from_pretrained(topic_save_path)

#             topic_model_classifier = pipeline("text-classification", model=topic_model, top_k=1, tokenizer=topic_tokenizer)
#             sentiment_save_path = 'latest_sentiment_model'
#             sentiment_model = AutoModelForSequenceClassification.from_pretrained(sentiment_save_path)
#             sentiment_tokenizer = BertTokenizer.from_pretrained(sentiment_save_path)

#             sentiment_model_classifier = pipeline("text-classification", model=sentiment_model,
#                                                 tokenizer=sentiment_tokenizer, top_k=None)
            

#             topic_model_output = topic_model_classifier(journal_entry)
#             sentiment_model_output = sentiment_model_classifier(journal_entry)
#             threshold = 0.5
#             sentiment_model_threshold = [entry for sublist in sentiment_model_output for entry in sublist if entry['score'] >= threshold]
#             additional_data = {
#                 "topic_model_output": topic_model_output,
#                 "sentiment_model_output": sentiment_model_output
#             }
#             gemini_insights = gemini_model.generate_journal_insights(journal_entry, additional_data=additional_data)

#             if not gemini_insights or gemini_insights.strip() == "":
#                 raise ValueError("Gemini model returned empty output.")

#             # Attempt to parse as JSON
#             try:
#                 parsed_insights = json.loads(gemini_insights)
#                 st.session_state.insights = {"gemini_analysis": parsed_insights}
#                 st.write("Insights Generated by Gemini (Parsed JSON):")
#                 st.json(parsed_insights)
#             except json.JSONDecodeError:
#                 # Fallback to plain text display if not JSON
#                 # st.warning("Gemini output is not in JSON format. Displaying raw text.")
#                 st.session_state.insights = {"gemini_analysis": gemini_insights}
#                 # insights = gemini_insights
#                 st.write("Insights Generated by Gemini:")
#                 st.text(gemini_insights)
#                 st.write("insights:", insights)

#         except Exception as e:
#             st.error(f"Failed to generate insights using Gemini: {str(e)}")

#     else:
#         st.warning("Please write something in the journal before analyzing!")


# # Step 5: Download Insights Button Logic
# if download_button:
#     if st.session_state.insights:
#         if isinstance(st.session_state.insights, dict):
#             # Convert dictionary to JSON string for download
#             insights_str = json.dumps(st.session_state.insights, indent=4)
#             mime_type = "application/json"
#             file_name = "journal_insights.json"
#         elif isinstance(st.session_state.insights, str):
#             # Use plain text if insights is a string
#             insights_str = st.session_state.insights
#             mime_type = "text/plain"
#             file_name = "journal_insights.txt"
#         else:
#             # Fallback for unknown data types
#             insights_str = str(st.session_state.insights)
#             mime_type = "text/plain"
#             file_name = "journal_insights.txt"
        
#         # Download button
#         st.download_button(
#             label="Download Insights",
#             data=insights_str,
#             file_name=file_name,
#             mime=mime_type
#         )
#     else:
#         st.warning("No insights to download. Please analyze your journal entry first!")


# # # Step 5: Download Button Logic
# # if download_button:
# #     if insights:
# #         insights_str = json.dumps(insights, indent=4)
# #         st.download_button(
# #             label="Download Insights",
# #             data=insights_str,
# #             file_name="journal_insights.json",
# #             mime="application/json"
# #         )
# #     else:
# #         st.warning("No insights to download. Please analyze your journal entry first!")

import streamlit as st
from transformers import pipeline
import json
from model.gemini_integrated import JournalInsightGenerator
from transformers import AutoModelForSequenceClassification, BertTokenizer, pipeline

# Step 2: Load Gemini Model
@st.cache_resource
def load_gemini_model():
    generator = JournalInsightGenerator()
    generator.one_shot_prompt()  # Initialize nowith one-shot prompt
    return generator

gemini_model = load_gemini_model()

# Step 3: Streamlit App Layout
st.title("DailyInks")

# Initialize session state for insights
if "insights" not in st.session_state:
    st.session_state.insights = None

# Text Area for Journaling
journal_entry = st.text_area("Write your journal entry below:")

# Buttons for actions
analyze_button = st.button("Analyze Insights")

# Step 4: Analyze Insights Button Logic
if analyze_button:
    if journal_entry.strip():
        st.write("Analyzing your journal entry...")
        try:
            topic_save_path = 'model\\topic_model'
            topic_model = AutoModelForSequenceClassification.from_pretrained(topic_save_path)
            topic_tokenizer = BertTokenizer.from_pretrained(topic_save_path)

            topic_model_classifier = pipeline("text-classification", model=topic_model, top_k=1, tokenizer=topic_tokenizer)
            sentiment_save_path = 'model\\sentiment_model'
            sentiment_model = AutoModelForSequenceClassification.from_pretrained(sentiment_save_path)
            sentiment_tokenizer = BertTokenizer.from_pretrained(sentiment_save_path)

            sentiment_model_classifier = pipeline("text-classification", model=sentiment_model,
                                                  tokenizer=sentiment_tokenizer, top_k=None)

            topic_model_output = topic_model_classifier(journal_entry)
            sentiment_model_output = sentiment_model_classifier(journal_entry)
            threshold = 0.5
            sentiment_model_threshold = [entry for sublist in sentiment_model_output for entry in sublist if entry['score'] >= threshold]
            additional_data = {
                "topic_model_output": topic_model_output,
                "sentiment_model_output": sentiment_model_output
            }
            gemini_insights = gemini_model.generate_journal_insights(journal_entry, additional_data=additional_data)

            if not gemini_insights or gemini_insights.strip() == "":
                raise ValueError("Gemini model returned empty output.")

            # Attempt to parse as JSON
            try:
                parsed_insights = json.loads(gemini_insights)
                st.session_state.insights = {"gemini_analysis": parsed_insights}
                st.write("Insights Generated by Gemini (Parsed JSON):")
                st.json(parsed_insights)
            except json.JSONDecodeError:
                # Fallback to plain text display if not JSON
                st.session_state.insights = {"gemini_analysis": gemini_insights}
                st.write("Insights Generated by Gemini:")
                st.text(gemini_insights)

        except Exception as e:
            st.error(f"Failed to generate insights using Gemini: {str(e)}")

    else:
        st.warning("Please write something in the journal before analyzing!")

# Step 5: Checkbox for Displaying Download Button
# show_download = st.checkbox("Allow ")

# Conditionally Render Download Button
if st.session_state.insights:
    if isinstance(st.session_state.insights, dict):
        # Convert dictionary to JSON string for download
        insights_str = json.dumps(st.session_state.insights, indent=4)
        mime_type = "application/json"
        file_name = "journal_insights.json"
    elif isinstance(st.session_state.insights, str):
        # Use plain text if insights is a string
        insights_str = st.session_state.insights
        mime_type = "text/plain"
        file_name = "journal_insights.txt"
    else:
        # Fallback for unknown data types
        insights_str = str(st.session_state.insights)
        mime_type = "text/plain"
        file_name = "journal_insights.txt"

    # Render download button
    st.download_button(
        label="Download Insights",
        data=insights_str,
        file_name=file_name,
        mime=mime_type
    )

